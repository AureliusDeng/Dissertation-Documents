{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\ldeng\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.894 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "#coding=utf-8\n",
    "import re\n",
    "import jieba as jb\n",
    "import os\n",
    "def stopwordslist(filepath):\n",
    "    stopwords = [line.strip() for line in open(filepath, 'r', encoding='utf-8').readlines()]\n",
    "    return stopwords\n",
    " \n",
    "# 对句子进行分词\n",
    "def seg_sentence(sentence):\n",
    "    sentence = re.sub(u'[0-9\\.]+', u'', sentence)\n",
    "    '''jb.add_word('光线摄影学院')        # 这里是加入用户自定义的词来补充jieba词典。\n",
    "    jb.add_word('曾兰老师')         # 同样，如果你想删除哪个特定的未登录词，就先把它加上然后放进停用词表里。\n",
    "    jb.add_word('网页链接')\n",
    "    jb.add_word('E%')\n",
    "    jb.add_word('https')\n",
    "    jb.add_word('微博视频')'''\n",
    "    sentence_seged = jb.cut(sentence.strip())\n",
    "    stopwords = stopwordslist('stopwords_cn_en.txt')  # 这里加载停用词的路径\n",
    "    outstr = ''\n",
    "    for word in sentence_seged:\n",
    "        if word not in stopwords and word.__len__()>1:\n",
    "            if word != '\\t':\n",
    "                outstr += word\n",
    "                outstr += \" \"\n",
    "    return outstr\n",
    " \n",
    "def seg_file(input_file,output_file):#单个txt\n",
    "    inputs = open(input_file, 'r', encoding='utf-8')\n",
    "    outputs = open(output_file, 'w',encoding='utf-8')\n",
    "    for line in inputs:\n",
    "        line_seg = seg_sentence(line)  # 这里的返回值是字符串\n",
    "        outputs.write(line_seg + '\\n')\n",
    "    outputs.close()\n",
    "    inputs.close()\n",
    " \n",
    "def seg_dir(input_dir,output_dir):#整个文件夹\n",
    "    filelist=os.listdir(input_dir)\n",
    "    for files in filelist:\n",
    "        inputs = open(input_dir+'/'+files, 'r', encoding='utf-8')\n",
    "        outputs = open(output_dir+'/'+files, 'w',encoding='utf-8')\n",
    "        for line in inputs:\n",
    "            line_seg = seg_sentence(line)  # 这里的返回值是字符串\n",
    "            outputs.write(line_seg + '\\n')\n",
    "        outputs.close()\n",
    "        inputs.close()\n",
    " \n",
    " \n",
    "seg_dir(\"original_input\",\"processed_input\")\n",
    "#seg_file(\"original_input/绍兴.txt\",\"processed_input/绍兴.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\n",
      "  \"中國\" (0.015)\n",
      "  \"新疆\" ( 0.011)\n",
      "  \"他們\" ( 0.009)\n",
      "  \"独立\" ( 0.008)\n",
      "  \"支持\" ( 0.008)\n",
      "  \"美國\" ( 0.006)\n",
      "  \"中共\" ( 0.006)\n",
      "  \"BBC\" ( 0.005)\n",
      "  \"一個\" ( 0.005)\n",
      "  \"北爱尔兰\"( 0.005)\n",
      "1:\n",
      "  \"BBC\" (0.033)\n",
      "  \"China\" ( 0.013)\n",
      "  \"people\" ( 0.010)\n",
      "  \"news\" ( 0.008)\n",
      "  \"Chinese\" ( 0.007)\n",
      "  \"Xinjiang\" ( 0.007)\n",
      "  \"UK\" ( 0.006)\n",
      "  \"fake\" ( 0.005)\n",
      "  \"The\" ( 0.005)\n",
      "  \"滤镜\"( 0.005)\n",
      "2:\n",
      "  \"新疆\" (0.029)\n",
      "  \"中国\" ( 0.021)\n",
      "  \"他们\" ( 0.019)\n",
      "  \"教育\" ( 0.013)\n",
      "  \"西方\" ( 0.012)\n",
      "  \"恐怖分子\" ( 0.012)\n",
      "  \"你们\" ( 0.009)\n",
      "  \"BBC\" ( 0.008)\n",
      "  \"支持\" ( 0.008)\n",
      "  \"国家\"( 0.007)\n",
      "3:\n",
      "  \"我们\" (0.029)\n",
      "  \"Ireland\" ( 0.014)\n",
      "  \"Northern\" ( 0.011)\n",
      "  \"freedom\" ( 0.011)\n",
      "  \"Scotland\" ( 0.010)\n",
      "  \"independence\" ( 0.010)\n",
      "  \"When\" ( 0.008)\n",
      "  \"人口\" ( 0.003)\n",
      "  \"BBC\" ( 0.003)\n",
      "  \"建议\"( 0.003)\n",
      "4:\n",
      "  \"你们\" (0.036)\n",
      "  \"中国\" ( 0.020)\n",
      "  \"英国\" ( 0.019)\n",
      "  \"穆斯林\" ( 0.018)\n",
      "  \"新疆\" ( 0.016)\n",
      "  \"国家\" ( 0.013)\n",
      "  \"自己\" ( 0.012)\n",
      "  \"他们\" ( 0.012)\n",
      "  \"BBC\" ( 0.010)\n",
      "  \"我们\"( 0.010)\n"
     ]
    }
   ],
   "source": [
    "#coding=utf-8\n",
    "import codecs\n",
    "import os\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "from gensim.corpora import Dictionary\n",
    " \n",
    "def classify(file):\n",
    "    train = []\n",
    "    fp = codecs.open('processed_input/'+file,'r',encoding='utf8')\n",
    "    for line in fp:\n",
    "        if line != '':\n",
    "            line = line.split()\n",
    "            train.append([w for w in line])\n",
    " \n",
    "    dictionary = corpora.Dictionary(train)\n",
    " \n",
    "    corpus = [dictionary.doc2bow(text) for text in train]\n",
    " \n",
    "    lda = LdaModel(corpus=corpus, id2word=dictionary, num_topics=5, passes=100)\n",
    "    # num_topics：主题数目\n",
    "    # passes：训练伦次\n",
    "    # num_words：每个主题下输出的term的数目\n",
    " \n",
    "    if os.path.exists('txt_output/'+file):\n",
    "        os.remove('txt_output/'+file)\n",
    "    f=open('txt_output/'+file,'w',encoding='utf-8')\n",
    "    for topic in lda.print_topics(num_words = 10):\n",
    "        termNumber = topic[0]\n",
    "        print(topic[0], ':', sep='')\n",
    "        f.write(str(topic[0])+':\\n')#输出保存到文件\n",
    "        listOfTerms = topic[1].split('+')\n",
    "        for term in listOfTerms:\n",
    "            listItems = term.split('*')\n",
    "            result='  '+listItems[1]+'('+str(listItems[0])+')'\n",
    "            print(result)\n",
    "            f.write(result+'\\n')#输出保存到文件\n",
    "    f.close()\n",
    "classify('xk.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\pandas\\compat\\_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\scipy\\io\\matlab\\mio5.py:98: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  from .mio5_utils import VarReader5\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:35: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps,\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:597: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:836: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1097: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1344: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1480: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:152: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  precompute=False, eps=np.finfo(np.float).eps,\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:320: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, random_state=None,\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:580: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=4 * np.finfo(np.float).eps, n_jobs=None,\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:31: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  EPS = np.finfo(np.float).eps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\n",
      "  \"BBC\" (0.025)\n",
      "  \"China\" ( 0.014)\n",
      "  \"people\" ( 0.011)\n",
      "  \"Chinese\" ( 0.008)\n",
      "  \"Xinjiang\" ( 0.007)\n",
      "  \"UK\" ( 0.006)\n",
      "  \"The\" ( 0.005)\n",
      "  \"terrorists\" ( 0.005)\n",
      "  \"country\" ( 0.004)\n",
      "  \"When\"( 0.004)\n",
      "1:\n",
      "  \"Ireland\" (0.014)\n",
      "  \"Northern\" ( 0.011)\n",
      "  \"news\" ( 0.011)\n",
      "  \"Scotland\" ( 0.010)\n",
      "  \"independence\" ( 0.010)\n",
      "  \"wwwyoutubecom\" ( 0.009)\n",
      "  \"watch\" ( 0.009)\n",
      "  \"youtube\" ( 0.008)\n",
      "  \"freedom\" ( 0.008)\n",
      "  \"滤镜\"( 0.007)\n",
      "2:\n",
      "  \"新疆\" (0.026)\n",
      "  \"中国\" ( 0.011)\n",
      "  \"教育\" ( 0.011)\n",
      "  \"BBC\" ( 0.009)\n",
      "  \"他们\" ( 0.008)\n",
      "  \"民族\" ( 0.007)\n",
      "  \"宗教\" ( 0.007)\n",
      "  \"共产党\" ( 0.006)\n",
      "  \"我们\" ( 0.006)\n",
      "  \"集中营\"( 0.005)\n",
      "3:\n",
      "  \"你们\" (0.037)\n",
      "  \"中国\" ( 0.026)\n",
      "  \"他们\" ( 0.020)\n",
      "  \"我们\" ( 0.018)\n",
      "  \"新疆\" ( 0.018)\n",
      "  \"英国\" ( 0.016)\n",
      "  \"国家\" ( 0.015)\n",
      "  \"穆斯林\" ( 0.014)\n",
      "  \"BBC\" ( 0.012)\n",
      "  \"支持\"( 0.011)\n",
      "4:\n",
      "  \"新疆\" (0.016)\n",
      "  \"中國\" ( 0.014)\n",
      "  \"他們\" ( 0.009)\n",
      "  \"BBC\" ( 0.008)\n",
      "  \"中共\" ( 0.006)\n",
      "  \"教育\" ( 0.006)\n",
      "  \"美國\" ( 0.006)\n",
      "  \"西方\" ( 0.006)\n",
      "  \"一個\" ( 0.005)\n",
      "  \"自己\"( 0.005)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py:247: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  by='saliency', ascending=False).head(R).drop('saliency', 1)\n"
     ]
    }
   ],
   "source": [
    "#coding=utf-8\n",
    "import codecs\n",
    "import os\n",
    " \n",
    "import gensim\n",
    "import OpenSSL.crypto\n",
    "import pyLDAvis.gensim_models\n",
    "from gensim import corpora, models\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    " \n",
    " \n",
    "def visualize(file):\n",
    "    train = []\n",
    "    fp = codecs.open('processed_input/'+file,'r',encoding='utf8')\n",
    "    for line in fp:\n",
    "        if line != '':\n",
    "            line = line.split()\n",
    "            train.append([w for w in line])\n",
    " \n",
    "    dictionary = corpora.Dictionary(train)\n",
    " \n",
    "    corpus = [dictionary.doc2bow(text) for text in train]\n",
    " \n",
    "    lda = LdaModel(corpus=corpus, id2word=dictionary, num_topics=5, passes=100)\n",
    "    # num_topics：主题数目\n",
    "    # passes：训练伦次\n",
    "    # num_words：每个主题下输出的term的数目\n",
    " \n",
    "    if os.path.exists('txt_output/'+file):\n",
    "        os.remove('txt_output/'+file)\n",
    "    f=open('txt_output/'+file,'w',encoding='utf-8')\n",
    "    for topic in lda.print_topics(num_words = 10):\n",
    "        termNumber = topic[0]\n",
    "        print(topic[0], ':', sep='')\n",
    "        f.write(str(topic[0])+':\\n')#输出保存到文件\n",
    "        listOfTerms = topic[1].split('+')\n",
    "        for term in listOfTerms:\n",
    "            listItems = term.split('*')\n",
    "            result='  '+listItems[1]+'('+str(listItems[0])+')'\n",
    "            print(result)\n",
    "            f.write(result+'\\n')#输出保存到文件\n",
    "    f.close()\n",
    "    #dictionary = gensim.corpora.Dictionary.load('lda.dict')\n",
    "    #corpus = gensim.corpora.MmCorpus('lda.mm')\n",
    "    #lda = models.ldamodel.LdaModel.load('lda.lda')\n",
    "    vis = pyLDAvis.gensim_models.prepare(lda, corpus, dictionary)\n",
    "    pyLDAvis.save_html(vis, 'html_output/'+file[:-4]+'.html')\n",
    " \n",
    "visualize(\"xk.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
